# -*- coding: utf-8 -*-
"""replicate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HMiNb4QYE4B-y5Ep3QlSOhUIoJ7QMu-w
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.model_selection as model_selection
from sklearn import metrics
from sklearn.model_selection import KFold, cross_val_score
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score
import lightgbm as lgb
# %matplotlib inline

parser= argparse.ArgumentParser()

parser.add_argument("--train_set", "--train_set", help="train set path")
parser.add_argument("--test_set", "--test_set", help="test set path")

args = parser.parse_args()

print( "train {} test {} ".format(args.train_set,args.test_set))

train=r'%s'%args.train_set
test=r'%s'%args.test_set
porto=pd.read_csv(train)
testdata=pd.read_csv(test)

print(porto.head())

print(testdata.head())

portowtnan=porto.replace(-1,np.nan)

portowtnan['missingmark']=portowtnan.isnull().sum(1) #add missing mark

portowtnan.replace(np.nan,-1,inplace=True)

portowtnan.drop(columns=['ps_car_03_cat','id'],axis=1,inplace=True) #drop columns with more than 50% null values
target=portowtnan['target']
portowtnan.drop(columns=['target'],axis=1,inplace=True)
cols=portowtnan.columns

portoclean=portowtnan
portoclean.head()

portocalc=[cols for cols in portoclean.columns if cols.find("calc")!=-1 and cols.find("13")==-1] #calc_13 is found to be boosting our prediction accuracy, therefore we keep it
portocalc

portoclean.drop(portocalc,axis=1,inplace=True)

portobin=[cols for cols in portoclean.columns if cols.find("bin")!=-1 ] #dataset seggregation
portocat=[cols for cols in portoclean.columns if cols.find("cat")!=-1 ]
portonormal=[cols for cols in portoclean.columns if cols.find("bin")==-1 & cols.find("cat")==-1 ]

portobin

prbin=portoclean.loc[:,portobin]

selected=portobin

portocat

prcat=portoclean.loc[:,portocat]
prcat

def calculatefreq(selectcat,df): #frequency encoding
  for col in selectcat:
    newcol='%s_freq'%(col)    
    m=portoclean[col].astype('category').value_counts(dropna=False).to_dict()
    df[newcol]=df[col].map(m)
  elem=[cols for cols in selectcat if cols.find("car")!=-1 ]   #adding logic to calculate car column
  df['car']=np.zeros(len(df))
  for col in elem:
    df['car']=df['car']+df[col]**.5
  return(df)

selectcat=portocat

prfreq=calculatefreq(selectcat,prcat)

prcat=prfreq
selectcat=prfreq.columns

prcat.columns

portonormal

prnor=portoclean.loc[:,portonormal]

selectednorm=portonormal

def featureengineering(df): #feature engineering as before
  top=['ps_car_14','ps_car_15','ps_reg_03','ps_ind_15']
  i=0
  for col in top:
    new='%d'%i
    new1='%d_interac'%i   
    m=portoclean.groupby(col)['ps_car_13'].mean().to_dict()      
    df[new]=df[col].map(m)
    df[new1]=(df['ps_car_13']*df[col])   
    i=i+1  
  tenco=pd.DataFrame()
  tenco['target']=target
  cat=['ps_car_11_cat','ps_car_06_cat']
  for col in cat:
   tenco[col]=prcat[col]
   m=(tenco.groupby(col)['target'].mean()).to_dict()
   newcol='%s_new'%col
   df[newcol]=df[col].map(m)
  listcol=[cols for cols in portoclean.columns if cols.find("ind")!=-1 ] #logic for calculating column ind
  df['ind']=np.zeros(len(df))
  for col in listcol:
    df['ind']=df['ind']+df[col]  
  df['ind']=df['ind']**2
  return df

features_train=pd.concat([prbin,prcat,prnor],join='outer',axis=1)
selectedfeatures=pd.concat([pd.Series(selected),pd.Series(selectcat),pd.Series(selectednorm)],axis=0,ignore_index=True)

features_train=featureengineering(features_train.copy())
features_train

def ginic(actual, pred):
    actual = np.asarray(actual) 
    n = len(actual)
    a_s = actual[np.argsort(pred)]
    a_c = a_s.cumsum()
    giniSum = a_c.sum() / a_s.sum() - (n + 1) / 2.0
    return giniSum / n
 
def gini_normalizedc(a, p):
    if p.ndim == 2:
        p = p[:,1] 
    return ginic(a, p) / ginic(a, a)

#0.27854 0.29230  #our best model on the private leadearboard
lg=lgb.LGBMClassifier(boosting_type='gbdt',learning_rate=.01,max_depth=6,n_estimators=1400,colsample_bytree=.3,reg_alpha=3, reg_lambda=3)

modelgb=lg.fit(features_train,target)

id=testdata['id']

testdata.replace(-1,np.nan,inplace=True)

testdata['missingmark']=testdata.isnull().sum(1)
testdata.replace(np.nan,-1,inplace=True)

testdata.drop(columns=portocalc,axis=1,inplace=True)

testdata.drop(columns=['id','ps_car_03_cat'],axis=1,inplace=True)

testdata.head()

testbin=testdata.loc[:,selected].copy()
testbin

testnor=testdata.loc[:,selectednorm].copy()
testnor

testcatfreq=calculatefreq(portocat,testdata)

testcat=testcatfreq.loc[:,selectcat].copy()
testcat

testcat.nunique()

test1=pd.concat([testbin,testcat,testnor],join='outer',axis=1)

test1=featureengineering(test1.copy())

predictionprob1=pd.DataFrame(modelgb.predict_proba(test1))
predictionprob1

predictionfinal=pd.DataFrame(id,columns=['id'])
predictionfinal['target']=predictionprob1.iloc[:,1]
predictionfinal

predictionfinal.to_csv('submission.csv',index=False)